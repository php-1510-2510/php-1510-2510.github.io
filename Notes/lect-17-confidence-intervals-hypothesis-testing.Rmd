---
title       : Hypothesis Testing
author      : Adam J Sullivan 
job         : Assistant Professor of Biostatistics
work        : Brown University
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js # {highlight.js, prettify, highlight}
hitheme     :  github     # 
widgets     : [mathjax, quiz, bootstrap, interactive] # {mathjax, quiz, bootstrap}
ext_widgets : {rCharts: [libraries/nvd3, libraries/leaflet, libraries/dygraphs]}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
logo        : publichealthlogo.png
biglogo     : publichealthlogo.png
assets      : {assets: ../../assets}
---  .segue bg:grey


```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(warning=FALSE)
knitr::opts_chunk$set(message=FALSE)
knitr::opts_chunk$set(results="hold")
knitr::opts_chunk$set(cache=FALSE)
library(ggplot2)
library(fivethirtyeight)
require(tidyverse)
library(broom)
```

# Hypothesis Testing

--- .class #id

## Hypothesis Testing Recap

- Let's consider our last hypothesis test. 
- We were wondering whether mental health days were associated with emotional support. 


```{r}
load("../Notes/Data/organic.rda")
organic
```


--- .class #id

## What could be happening?

- Emotional Support influences mental health days. 
- Groups differed at Baseline. 
- Random Chance

--- .class #id

## What have we done so far?

- We have ran multiple permutations and determined that this was not due to random chance. 
- We also created bootstrapped confidence intervals and determined that this was not due to chance. 
- Why did we use 95% confidence intervals? 
- What does 95% have to do with hypothesis testing? 

--- .class #id

## What is Hypothesis Testing? 

- *Hypothesis testing* is a procedure where claims about the value of a population parameter (such as $\mu$ or $\pi$) may be considered using the evidence from the sample.  
- Two competing statements, or *hypotheses*, are crafted about the parameter value:
    - The *null hypothesis* $H_0$ is the status quo hypothesis, representing what has been assumed about the value of the parameter.
    - The *alternative hypothesis* represents the alternative claim about the value of the parameter.


--- .class #id

## What do we get from this? 

- We typically have drawn two possible conclusions
    - Reject $H_0$
    - Fail to reject $H_0$ based on a *p*-value. (Typically *p*-value < 0.05)


--- .class #id

## Why 0.05

- Consider a court case. 
- In many court systems it is said that a defendant is innocent until proven guilty. 
- This means:
$$ H_0: \text{Defendant is innocent} \hspace{.75cm} \text{vs.} \hspace{.75cm} H_a: \text{Defendant is guilty} $$


--- .class #id


## What our the outcomes? 

![](../Notes/figure/hyp-test-table.PNG)


--- .class #id

## What are the possible outcomes? 

- There are four possible outcomes of a criminal trial with respect to the jury's decision, and what is true in reality.

- Correct decisions:
    - Do not reject $H_0$ if there is not enough evidence against the defendant. The jury acquits an innocent person.
    - Reject $H_0$ if there is sufficient evidence against the defendant. The jury convicts a guilty person.

--- .class #id

## What are the possible outcomes? 

- Erroneous decisions:
    - Type I error: Reject $H_0$ when $H_0$ is true. The jury convicts an innocent person.
    - Type II error: Do not reject $H_0$ when $H_0$ is false. The jury acquits a guilty person.

--- .class #id

## Notation in Statistics

- The probability of a Type I error is denoted as $\alpha$.
- The probability of a Type II error is denoted as $\beta$. 
- For the same sample size,  decrease in $\alpha$ leads to a decrease in $\beta$. 
- Most of the time $\alpha$ is fixed at 0.05. 

--- .class #id

## What does this mean? 

- We decide it is most important to fix $\alpha$. 
- Why?

--- .class #id

## Type I Error

- We believe it is more important to fix the amount of type I error.
- Remember the Type I error is the act of finding an innocent person guilty. 
- This means we find it worse to convict an innocent person than to let a guilty person go free. 

--- .class #id

## How does $\alpha$ come into play? 

- Recall how we made the confidence intervl. 
- We did the following: 
$$\bar{x} \pm \text{Margin of Error}$ 
- How was this done:

$$\bar{x} \pm t_{\alpha/2, n-1} \dfrac{S}{\sqrt{n}}$$

--- .class #id

## The $t$-test

- We know that
$$ t= \dfrac{\bar{x} - \mu_0}{s/\sqrt{n}}$$
- Where
    - $\bar{x}$ is the sample mean
    - $\mu_0$ is the population average stated in the null hypothesis. 
    - $s$ is the sample standard deviation. 
    - $n$ is the sample size. 


--- .class #id

## What does the $t$ mean?

- The value of *t* is interpreted as the number of standard errors above or below the hypothesized mean $\mu_0$. 
- When *t* is large, it provides supporting evidence against the null hypothesis $H_0$. 
- How do we determing if we have enough supporting evidence to reject $H_0$?  
- This is measured by the *p*-value.


--- .class #id

## What is the p-value?

- The *p*-value is the probability of observing a sample statistic (such as $\bar x$) at least as extreme as the statistic actually observed, if we assume $H_0$ is true.  
- This is the clarified version by the way. 

--- .class #id

## What does the *p*-value tell us?

- Thus, a *p*-value of 0.05 suggests there is only a 5% probability of observing $\bar x$ if the population value is actually $\mu_0$ as $H_0$ suggests.  
- The smaller the *p*-value, the smaller the probability that $\bar x$ aligns with the null hypothesis $H_0$.  


--- .class #id

## How does this work in practice?

- We know some stuff. 
- We want to know some more. 
- We design an experiment. 
- We collect data from the experiement. 
- We then summarize the results, *Statistic*


--- .class #id


## The One Sample $t$ test

$$ t = \dfrac{\bar{x}-\mu_0}{s/\sqrt{n}}$$

- We use this to compare one sample of data versus a suggested population mean. 
- We will do this in R. 


--- .class #id

## One Sample $t$ test in R

```
t.test(x, mu, data )
```

- Where
    - `x` is a vector of data. 
    - `mu` is the population mean under the null. 
    - `data` optional dataframe where the vector `x` is contained. 

--- .class #id
  
## SAT scores

- You are a math teacher and have scores from the math portion of the SAT. 
- The average for this position is listed as 527. 
- You wish to know if you students score is higher, lower or the same as the avera. 


--- .class #id

## The test

```{r}
sat <- c(527, 554, 534, 541, 539, 542, 498, 512, 528, 531, 
563, 566, 498, 503, 551, 582, 529, 549, 571, 523, 543, 588, 571)

```

--- .class #id

## Data Distribution

```{r sat-dist, echo=F}
library(ggplot2)
ggplot(data=NULL, aes(x=sat)) + 
      geom_density(fill="lightblue", color="skyblue", alpha=0.5) + 
      theme_minimal()
```



--- .class #id

## The Hypothesis

- We would consider the following hypothesis

$$H_0: \text{ Our class has the average of 527} \text{ vs } H_1: \text{ Our class has a different Average} $$

- Also:

$$ H_0: \mu = 527 \text{ vs } H_1: \mu\ne 527$$



--- .class #id

## The test 

```{r}

t.test(x=sat, mu=527)
```



--- .class #id

## What do we see? 

- $t$ statistic is 2.6516
- *p*-value 0.01458
- 95% CI: (530.0501, 551.9499)
- Mean of class: 541

--- .class #id

## Evaluating Results

- We can check the confidence interval. 
- We look to see if the suggested mean is in the CI. 
- It is not in the CI so we would suggest that our sample is different from the mean. 
- We would conclude that it is higher. 

--- .class #id

## Evaluating Results

- We could consider the *p*-value. 
- If we are considering a significance level of 0.05, then we would reject the null hypothesis since the p-value is 0.01458. 
- We then know our average is different from the rest of the population. 
- The reported mean is 541, suggesting our class is higher than the rest of the population. 

--- .class #id

## The hypothesis

- We tested what was called a 2-sided hypothesis. 
- This means that we allow for the alternative to be:

$$H_1 \mu\ne 527$$

- Other forms of the alternative may be

$$H_1\text{: } \mu>527$$
$$H_1\text{: } \mu<527$$
- We prefer 2-sided

--- .class #id

## Why 2-sided? 

- We must first see how we calculated p-value. 
- By allowing for the average to be above or  below, we are not sure whether the tails are higher or lower. 
- Remember our *t* statistic of 2.65


--- .class #id


## The picture


```{r t-dist-sat-hyp, echo=F, fig.height=4}
ggplot(NULL, aes(c(-3,3))) +
  geom_area(stat = "function", fun = dt, args = list(df = 22),  fill = "grey80", xlim = c(-4, -2.65)) +
  geom_area(stat = "function", fun = dt, args = list(df = 22), fill = "#00998a", xlim = c(-2.65, 2.65)) +
  geom_area(stat = "function", fun = dt,  args = list(df = 22),fill = "grey80", xlim = c(2.65, 4)) +
  labs(x = "t (df=22)", y = "") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = c(-2.65,2.65))
```


--- .class #id

## The area to the right:
  
- We can calculate this area:

```{R}
1- pt(2.6515, df=22)
```

--- .class #id 


## The area to the left:
  
- We can calculate this area:

```{R}
pt(-2.6516, df=22)
```


--- .class #id

## 2 p-values

- If we do a one-sided test then our *p*-value is the area to the right or the left depending on our alternative:
- Both of these have the area of 0.007
- If we use a two-sided we have both the left and right areas:
$$2*pt(-2.6516, df=22) = 0.0145743$$


--- .class #id

## What is the difference? 

- One sided *p*-values are half as much as the Two sided. 
- It is considered stronger evidence to allow for two sided. 




--- .class #id


## The 2 Sample $t$ test. 



$$ t=\dfrac{\bar{x}_1 - \bar{x}_2}{\sqrt{\dfrac{s_1^2}{n1} + \dfrac{s_2^2}{n_2}}}$$

- Where
    - $\bar{x}_1$ and $\bar{x}_2$ are the sample means of groups 1 and 2 respectively. 
    - $s_1^2$ and $s_2^2$ are the sample variances of groups 1 and 2 respectively. 
    - $n_1$ and $n_2$ are the sample sizes of groups 1 and 2 respectively. 


--- .class #id

## The 2 Sample $t$ test DF

$$\text{df}= \dfrac{\left(\dfrac{s_1^2}{n_1} + \dfrac{s_2^2}{n_2}\right)^2}{\dfrac{(s_1^2/n_1)^2}{n_1-1} + \dfrac{(s_2^2/n_1^2)^2}{n_2-1}}$$
 

--- .class #id

## Equal Variances

- Some people will display a different $t$ test where there are equal variances. 
- This was an easy way to do things by hand but is truly irrelevant with today's standards. 


--- .class #id

## Back to the BRFSS Data

- Let us consider the BRFSS data again:

```{R}
load("Data/brfss.rda")
brfss2
```

--- .class #id

## Difference in Unhealthy Days by General Health

```{r  unhealthy-by-gen-health, echo=F, fig.height=4}

ggplot(brfss2, aes(x=genhlth_bin, y = unhealthy.days)) + 
   geom_boxplot(aes(fill=genhlth_bin))
```


--- .class #id

## The test in R

```
t.test(formula, data, var.equal=FALSE)
```

- Where
    - `formula` is of the notion: $y\sim x$
    - `data` is the data frame. 
    - `var.equal=FALSE` is the fact that R assumes we do not believe variances are the same. 


--- .class #id


## The hypothesis

$$H_0\text{: The means of the groups are the same}$$
$$\text{ vs }$$
$$ H_1\text{: The means of the groups are different. }$$
or

$$H_0: \mu_1=\mu_2\text{ vs } \mu_1\ne\mu_2$$

or 
$$H_0: \mu_1-\mu_2=0\text{ vs } \mu_1-\mu_2\ne0$$


--- .class #id

## The test in R

```{r}
t.test(unhealthy.days~genhlth_bin, data=brfss2)
```

--- .class #id

## The results

- $t$ statistic: -35.503
- df: 1546.5
- *p*-value $<2.2x10^{-16}$
- 95% CI of difference: (-12.91, -11.56)
- Mean of Good Health: 3.95
- Mean of Bad Health: 16.18

--- .class #id

## Conclusion

- We can conclude that there is a difference in unhealthy days between the groups. 
- Based on the means, it appears that those who say they have good health on average have less unhealthy days than those who classify with fair or poor health. 



--- .class #id

## $t$-test Assumptions for 1 Sample

- $\bar{x}$ is normal with mean $\mu_0$
- $s^2$ follows a $\chi^2$ distribution with $n-1$ degrees of freedom. 
- $Z$ and $s$ are independent. 


--- .class #id

## $t$-test Assumptions for 2 sample

- Means of populations being compared should be normal. 
- Groups are independent of each other. 

