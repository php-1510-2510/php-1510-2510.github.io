---
title       : Hypothesis Testing
author      : Adam J Sullivan 
job         : Assistant Professor of Biostatistics
work        : Brown University
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js # {highlight.js, prettify, highlight}
hitheme     :  github     # 
widgets     : [mathjax, quiz, bootstrap, interactive] # {mathjax, quiz, bootstrap}
ext_widgets : {rCharts: [libraries/nvd3, libraries/leaflet, libraries/dygraphs]}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
logo        : publichealthlogo.png
biglogo     : publichealthlogo.png
assets      : {assets: ../../assets}
---  .segue bg:grey


```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(warning=FALSE)
knitr::opts_chunk$set(message=FALSE)
knitr::opts_chunk$set(results="hold")
knitr::opts_chunk$set(cache=FALSE)
library(ggplot2)
library(fivethirtyeight)
require(tidyverse)
library(broom)
```

# Hypothesis Testing

--- .class #id




## What our the outcomes? 

![](../Notes/figure/hyp-test-table.PNG)


--- .class #id

## What are the possible outcomes? 

- There are four possible outcomes of a criminal trial with respect to the jury's decision, and what is true in reality.

- Correct decisions:
    - Do not reject $H_0$ if there is not enough evidence against the defendant. The jury acquits an innocent person.
    - Reject $H_0$ if there is sufficient evidence against the defendant. The jury convicts a guilty person.

--- .class #id

## What are the possible outcomes? 

- Erroneous decisions:
    - Type I error: Reject $H_0$ when $H_0$ is true. The jury convicts an innocent person.
    - Type II error: Do not reject $H_0$ when $H_0$ is false. The jury acquits a guilty person.

--- .class #id

## Notation in Statistics

- The probability of a Type I error is denoted as $\alpha$.
- The probability of a Type II error is denoted as $\beta$. 
- For the same sample size,  decrease in $\alpha$ leads to a decrease in $\beta$. 
- Most of the time $\alpha$ is fixed at 0.05. 

--- .class #id

## One Sided Hypothesis Test

```{R hyp-test-norm-1, echo=FALSE, fig.width=16}
library(ggplot2)
library(latex2exp)


ggplot(NULL, aes(c(-1,1))) +
  geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "lightgrey", xlim = c(-0.4,0.4)) +
  geom_area(stat = "function", fun = dnorm, args = list(0.5, 0.05), fill = "lightgrey", xlim = c(0.4, 1)) +
  geom_area(stat = "function", fun = dnorm, args = list(0.5, 0.05), fill = "forestgreen", xlim = c(-0.4, 0.4)) + 
  geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "goldenrod", xlim = c(0.4,1)) +
  labs(x = "", y = "") +
  geom_vline(xintercept=0.4, color="red") + 
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) + 
  theme_minimal() + 
  annotate(geom="text", x=0.5, y=8.5, label="H1", color="black") +
  annotate(geom="text", x=0.5, y=-0.2, label="Type I Error", color="goldenrod") +
  annotate(geom="text", x=0.2, y=4.5, label="H0", color="black") + 
  annotate(geom="text", x=0.3, y=-0.2, label="Type II Error", color="forestgreen") + 
  annotate(geom="text", x=0.395, y=-0.6, label="Critical   Value", color="red") 
  
```



--- .class #id

## One Sided Hypothesis Test

```{R hyp-test-norm-2, echo=FALSE, fig.width=16}
library(ggplot2)
library(latex2exp)


ggplot(NULL, aes(c(-1,1))) +
  geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "lightgrey", xlim = c(-0.4,0.46)) +
  geom_area(stat = "function", fun = dnorm, args = list(0.5, 0.05), fill = "lightgrey", xlim = c(0.46, 1)) +
  geom_area(stat = "function", fun = dnorm, args = list(0.5, 0.05), fill = "forestgreen", xlim = c(-0.4, 0.46)) + 
  geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "goldenrod", xlim = c(0.46,1)) +
  labs(x = "", y = "") +
  geom_vline(xintercept=0.46, color="red") + 
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) + 
  theme_minimal() + 
  annotate(geom="text", x=0.5, y=8.5, label="H1", color="black") +
  annotate(geom="text", x=0.55, y=-0.2, label="Type I Error", color="goldenrod") +
  annotate(geom="text", x=0.2, y=4.5, label="H0", color="black") + 
  annotate(geom="text", x=0.3, y=-0.2, label="Type II Error", color="forestgreen") + 
  annotate(geom="text", x=0.455, y=-0.6, label="Critical   Value", color="red") 
  
```



--- .class #id

## One Sided Hypothesis Test

```{R hyp-test-norm-3, echo=FALSE, fig.width=16}
library(ggplot2)
library(latex2exp)


ggplot(NULL, aes(c(-1,1))) +
  geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "lightgrey", xlim = c(-0.4,0.35)) +
  geom_area(stat = "function", fun = dnorm, args = list(0.5, 0.05), fill = "lightgrey", xlim = c(0.35, 1)) +
  geom_area(stat = "function", fun = dnorm, args = list(0.5, 0.05), fill = "forestgreen", xlim = c(-0.4, 0.35)) + 
  geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "goldenrod", xlim = c(0.35,1)) +
  labs(x = "", y = "") +
  geom_vline(xintercept=0.35, color="red") + 
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) + 
  theme_minimal() + 
  annotate(geom="text", x=0.5, y=8.5, label="H1", color="black") +
  annotate(geom="text", x=0.55, y=-0.2, label="Type I Error", color="goldenrod") +
  annotate(geom="text", x=0.2, y=4.5, label="H0", color="black") + 
  annotate(geom="text", x=0.3, y=-0.2, label="Type II Error", color="forestgreen") + 
  annotate(geom="text", x=0.345, y=-0.6, label="Critical   Value", color="red") 
  
```




--- .class #id

## Two Sided Hypothesis Test

```{R hyp-test-norm-4, echo=FALSE, fig.width=16}
library(ggplot2)
library(latex2exp)


ggplot(NULL, aes(c(-1,1))) +
  geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "lightgrey", xlim = c(0,0.4)) +
  geom_area(stat = "function", fun = dnorm, args = list(0.5, 0.05), fill = "lightgrey", xlim = c(0.4, 1)) +
  geom_area(stat = "function", fun = dnorm, args = list(0.5, 0.05), fill = "forestgreen", xlim = c(-0.4, 0.4)) + 
  geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "goldenrod", xlim = c(0.4,1)) +
   geom_area(stat = "function", fun = dnorm, args = list(-0.1, 0.05), fill = "lightgrey", xlim = c(-0.5, 0)) +
   geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "goldenrod", xlim = c(-0.4,0)) +
  geom_area(stat = "function", fun = dnorm, args = list(-0.1, 0.05), fill = "forestgreen", xlim = c(0, 0.4)) +
  labs(x = "", y = "") +
  geom_vline(xintercept=0.4, color="red") +
  geom_vline(xintercept=0, color="red") + 
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) + 
  theme_minimal() + 
  annotate(geom="text", x=0.5, y=8.5, label="H1", color="black") +
  annotate(geom="text", x=-0.1, y=8.5, label="H1", color="black") +
  annotate(geom="text", x=0.5, y=-0.2, label="Type I Error", color="goldenrod") +
  annotate(geom="text", x=-0.1, y=-0.2, label="Type I Error", color="goldenrod") +
  annotate(geom="text", x=0.2, y=4.5, label="H0", color="black") + 
  annotate(geom="text", x=0.3, y=-0.2, label="Type II Error", color="forestgreen") + 
    annotate(geom="text", x=0.1, y=-0.2, label="Type II Error", color="forestgreen") + 
  annotate(geom="text", x=0.395, y=-0.6, label="Critical   Value", color="red") + 
   annotate(geom="text", x=0, y=-0.6, label="Critical   Value", color="red") 
  
```






--- .class #id

## Two Sided Hypothesis Test

```{R hyp-test-norm-5, echo=FALSE, fig.width=16}
library(ggplot2)
library(latex2exp)


ggplot(NULL, aes(c(-1,1))) +
  geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "lightgrey", xlim = c(0.04,0.36)) +
  geom_area(stat = "function", fun = dnorm, args = list(0.5, 0.05), fill = "lightgrey", xlim = c(0.36, 1)) +
  geom_area(stat = "function", fun = dnorm, args = list(0.5, 0.05), fill = "forestgreen", xlim = c(-0.36, 0.36)) + 
  geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "goldenrod", xlim = c(0.36,1)) +
   geom_area(stat = "function", fun = dnorm, args = list(-0.1, 0.05), fill = "lightgrey", xlim = c(-0.5, 0.04)) +
   geom_area(stat = "function", fun = dnorm,args = list(0.2, 0.1),  fill = "goldenrod", xlim = c(-0.36,0.04)) +
  geom_area(stat = "function", fun = dnorm, args = list(-0.1, 0.05), fill = "forestgreen", xlim = c(0.04, 0.36)) +
  labs(x = "", y = "") +
  geom_vline(xintercept=0.36, color="red") +
  geom_vline(xintercept=0.04, color="red") + 
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) + 
  theme_minimal() + 
  annotate(geom="text", x=0.5, y=8.5, label="H1", color="black") +
  annotate(geom="text", x=-0.1, y=8.5, label="H1", color="black") +
  annotate(geom="text", x=0.5, y=-0.2, label="Type I Error", color="goldenrod") +
  annotate(geom="text", x=-0.1, y=-0.2, label="Type I Error", color="goldenrod") +
  annotate(geom="text", x=0.2, y=4.5, label="H0", color="black") + 
  annotate(geom="text", x=0.3, y=-0.2, label="Type II Error", color="forestgreen") + 
    annotate(geom="text", x=0.1, y=-0.2, label="Type II Error", color="forestgreen") + 
  annotate(geom="text", x=0.395, y=-0.6, label="Critical   Value", color="red") + 
   annotate(geom="text", x=0, y=-0.6, label="Critical   Value", color="red") 
  
```


--- .class #id

## The $t$-test

- We know that
$$ t= \dfrac{\bar{x} - \mu_0}{s/\sqrt{n}}$$
- Where
    - $\bar{x}$ is the sample mean
    - $\mu_0$ is the population average stated in the null hypothesis. 
    - $s$ is the sample standard deviation. 
    - $n$ is the sample size. 


--- .class #id

## What does the $t$ mean?

- The value of *t* is interpreted as the number of standard errors above or below the hypothesized mean $\mu_0$. 
- When *t* is large, it provides supporting evidence against the null hypothesis $H_0$. 
- How do we determing if we have enough supporting evidence to reject $H_0$?  
- This is measured by the *p*-value.

--- .class #id
## The One Sample $t$ test

$$ t = \dfrac{\bar{x}-\mu_0}{s/\sqrt{n}}$$

- We use this to compare one sample of data versus a suggested population mean. 
- We will do this in R. 


--- .class #id

## One Sample $t$ test in R

```
t.test(x, mu, data )
```

- Where
    - `x` is a vector of data. 
    - `mu` is the population mean under the null. 
    - `data` optional dataframe where the vector `x` is contained. 

--- .class #id
  
## SAT scores

- You are a math teacher and have scores from the math portion of the SAT. 
- The average for this position is listed as 527. 
- You wish to know if you students score is higher, lower or the same as the average. 


--- .class #id

## The test

```{r}
sat <- c(527, 554, 534, 541, 539, 542, 498, 512, 528, 531, 
563, 566, 498, 503, 551, 582, 529, 549, 571, 523, 543, 588, 571)

```

--- .class #id

## Data Distribution

```{r sat-dist, echo=F}
library(ggplot2)
ggplot(data=NULL, aes(x=sat)) + 
      geom_density(fill="lightblue", color="skyblue", alpha=0.5) + 
      theme_minimal()
```



--- .class #id

## The Hypothesis

- We would consider the following hypothesis

$$H_0: \text{ Our class has the average of 527} \text{ vs } H_1: \text{ Our class has a different Average} $$

- Also:

$$ H_0: \mu = 527 \text{ vs } H_1: \mu\ne 527$$



--- .class #id

## The test 

```{r}

t.test(x=sat, mu=527)
```



--- .class #id

## What do we see? 

- $t$ statistic is 2.6516
- *p*-value 0.01458
- 95% CI: (530.0501, 551.9499)
- Mean of class: 541

--- .class #id

## Evaluating Results

- We can check the confidence interval. 
- We look to see if the suggested mean is in the CI. 
- It is not in the CI so we would suggest that our sample is different from the mean. 
- We would conclude that it is higher. 

--- .class #id

## Evaluating Results

- We could consider the *p*-value. 
- If we are considering a significance level of 0.05, then we would reject the null hypothesis since the p-value is 0.01458. 
- We then know our average is different from the rest of the population. 
- The reported mean is 541, suggesting our class is higher than the rest of the population. 


--- .class #id


## The 2 Sample $t$ test. 



$$ t=\dfrac{\bar{x}_1 - \bar{x}_2}{\sqrt{\dfrac{s_1^2}{n1} + \dfrac{s_2^2}{n_2}}}$$

- Where
    - $\bar{x}_1$ and $\bar{x}_2$ are the sample means of groups 1 and 2 respectively. 
    - $s_1^2$ and $s_2^2$ are the sample variances of groups 1 and 2 respectively. 
    - $n_1$ and $n_2$ are the sample sizes of groups 1 and 2 respectively. 


--- .class #id

## The 2 Sample $t$ test DF

$$\text{df}= \dfrac{\left(\dfrac{s_1^2}{n_1} + \dfrac{s_2^2}{n_2}\right)^2}{\dfrac{(s_1^2/n_1)^2}{n_1-1} + \dfrac{(s_2^2/n_1^2)^2}{n_2-1}}$$
 

--- .class #id

## Equal Variances

- Some people will display a different $t$ test where there are equal variances. 
- This was an easy way to do things by hand but is truly irrelevant with today's standards. 


--- .class #id

## Back to the BRFSS Data

- Let us consider the BRFSS data again:

```{R}
load("Data/brfss.rda")
brfss2
```

--- .class #id

## Difference in Unhealthy Days by General Health

```{r  unhealthy-by-gen-health, echo=F, fig.height=4}

ggplot(brfss2, aes(x=genhlth_bin, y = unhealthy.days)) + 
   geom_boxplot(aes(fill=genhlth_bin))
```


--- .class #id

## The test in R

```
t.test(formula, data, var.equal=FALSE)
```

- Where
    - `formula` is of the notion: $y\sim x$
    - `data` is the data frame. 
    - `var.equal=FALSE` is the fact that R assumes we do not believe variances are the same. 


--- .class #id


## The hypothesis

$$H_0\text{: The means of the groups are the same}$$
$$\text{ vs }$$
$$ H_1\text{: The means of the groups are different. }$$
or

$$H_0: \mu_1=\mu_2\text{ vs } \mu_1\ne\mu_2$$

or 
$$H_0: \mu_1-\mu_2=0\text{ vs } \mu_1-\mu_2\ne0$$


--- .class #id

## The test in R

```{r}
t.test(unhealthy.days~genhlth_bin, data=brfss2)
```

--- .class #id

## The results

- $t$ statistic: -35.503
- df: 1546.5
- *p*-value $<2.2x10^{-16}$
- 95% CI of difference: (-12.91, -11.56)
- Mean of Good Health: 3.95
- Mean of Bad Health: 16.18

--- .class #id

## Conclusion

- We can conclude that there is a difference in unhealthy days between the groups. 
- Based on the means, it appears that those who say they have good health on average have less unhealthy days than those who classify with fair or poor health. 



--- .class #id

## $t$-test Assumptions for 1 Sample

- $\bar{x}$ is normal with mean $\mu_0$
- $s^2$ follows a $\chi^2$ distribution with $n-1$ degrees of freedom. 
- $Z$ and $s$ are independent. 


--- .class #id

## $t$-test Assumptions for 2 sample

- Means of populations being compared should be normal. 
- Groups are independent of each other. 

--- .class #id

## Hypothesis Test of Proportions

- Many times we wish to hypothesis test proportions in a population. 
- We do this by doing a *z*-test. 
- We can use the *z* distribution rather than the *t* since with proportions when we know *p*, we know the standard deviation. 

--- .class #id

## The *Z*-test for a Single Proportion

$$z = \dfrac{p-\pi_0}{\sqrt{\dfrac{\pi_0(1-\pi)}{n}}}$$

- where
    - $p$ is the proportion of successes. 
    - $\pi_0$ is the hypothesized value of $p$. 
    - $n$ is the sample size. 


--- .class #id

## Attrition Data

- We will look at the attrition data. 
- This is part of the `rsample` package. 
- You can call it with the following code:

```{r}
attr_pop <- rsample::attrition
```


--- .class #id

## Attrition Data

- This data is about employee attrition. 
- Many times people are interested in looking into attrition rates as it could be a sign of unhealthy work environments. 
- Attrition can happen for normal reasons like retirement or it can be through resignation, ...

--- .class #id

## The Data

```{R}
str(attr_pop)
```


--- .class #id

## Questions we might ask? 

- Do people who leave make the company average of $6502 per month? 
- Do people who leave make the same as people who stay? 


--- .class #id

## Comparing Average

- Do people who leave make the company average of $6502 per month? 
    - First filter the data out. 
    - Second, do a t-test
    $$H_0: \mu=6502\text{vs }H_1: \mu\ne6502$$

```{r, eval=F}
library(dplyr)
income <- attr_pop %>%
      filter(Attrition=="Yes") %>%
      select(MonthlyIncome) %>%
      collect()

t.test(x=income, mu=6502)
```


--- .class #id

## Comparing Average


```{r, echo=F}
library(dplyr)
income <- attr_pop %>%
      filter(Attrition=="Yes") %>%
      select(MonthlyIncome) %>%
      collect()

t.test(x=income, mu=6502)
```



--- .class #id

## The Distribution

```{r income-dist-attr, echo=F}
library(ggplot2)
ggplot(data=income, aes(x=MonthlyIncome)) + 
      geom_density(fill="lightblue", color="skyblue", alpha=0.5) + 
      theme_minimal()
```

--- .class #id

## Do We Believe this based on the data? 

- The data looks skewed and the central limit theorem suggests that the mean is normal. 
- The t-test had enough of a sample, but we could consider bootstrap confidence intervals as well. 

--- .class ##id

## Bootstrapping Confidence Interval

```{r, echo=F}
library(rsample)
library(purrr)
library(ggplot2)
library(dplyr)
```
```{r}
set.seed(123)
bt_data <- bootstraps(income, times = 1000)
get_mean <- function(split) {
  # access to the sample data 
  split_data <- analysis(split)
  # calculate the sample mean value 
  split_mean <- mean(split_data$MonthlyIncome, na.rm=T)
  return(split_mean)
}
bt_data$bt_means <- map_dbl(bt_data$splits, get_mean)
```


--- .class #id

## Distribution of Bootstrap Means

```{r bt-means-att, echo=F}
ggplot(bt_data, aes(x = bt_means)) +  geom_density(fill="lightblue", color="skyblue", alpha=0.5) + 
      theme_minimal() + 
  xlab("Mean of Monthly Income")
```


--- .class #id

## Bootstrap Confidence Interval

```{R}
bt_ci <- round(quantile(bt_data$bt_means, c(0.025, 0.975)), 3)
bt_ci
```

--- .class #id

## Conclusions

- Those who left make less than the company average. 
- We can see this with
    - p.value: <0.0001
    - *t* dist CI: (4321, 5254)
    - Bootstrap CI: (4312, 5259)



--- .class #id

## Income of those who left vs stayed

```{r, eval=F}
t.test(MonthlyIncome~Attrition, data=attr_pop)
```

--- .class #id

## Income of those who left vs stayed

```{r, echo=F}
t.test(MonthlyIncome~Attrition, data=attr_pop)
```


--- .class #id

## Another Question

- Among employees do female employees make up 1/2 of the company? 
- Among those who leave, is there a difference in males vs females? 

--- .class #id

## Coding Tables

```{r, eval=F}
attr_pop %>%
  group_by(Gender, Attrition) %>%
  summarise(n = n()) %>%
  mutate(freq = n/sum(n))
```

--- .class #id

## Coding Tables

```{r, echo=F}
attr_pop %>%
  group_by(Gender, Attrition) %>%
  summarise(n = n()) %>%
  mutate(freq = n/sum(n))
```


--- .class #id

## Coding Tables

```{r, eval==F}
attr_pop %>%
  group_by(Attrition, Gender) %>%
  summarise(n = n()) %>%
  mutate(freq = n/sum(n))
```

--- .class #id

## Coding Tables

```{r, echo==F}
attr_pop %>%
  group_by(Gender, Attrition) %>%
  summarise(n = n()) %>%
  mutate(freq = n/sum(n))
```


--- .class #id

## Hypothesis Test on Proportions

- We have proportions and this is different from means. 
- Proportions are from a binomial distribution. 
- This means we can actually use the *z* distribution. 
- When we assume $H_0$ we assume a probability which gives us the true variance. 

--- .class #id

## Hypothesis Test on Proportions

$$z = \dfrac{\hat{p} - \pi_0}{\sqrt{\dfrac{\pi_0(1-\pi_0)}{n}}}$$

- Where
    - $z$ is the test statistic which is normally distributed. 
    - $\hat{p}$ is the sample proportion estimate. 
    - $\pi_0$ is the proportion under the Null hypothesis. 


--- .class #id 

## Are Female employees 50% of the employees?

$$H_0:\pi=0.5 \text{ vs } H_1: \pi\ne0.5$$

- We can do this in R

--- .class #id

## Proportion Test in R

```{r}
table(attr_pop$Gender) %>% prop.table()
```

--- .class #id

## Proportion Test in R

```{r}
table(attr_pop$Gender) %>% 
  prop.test()
```


--- .class #id


## Conclusions

- We can see that there is evidence that females do not make up half of the company. 
    - *p*-value <0.0001
    - 95% CI 0.37, 0.43)
    - Mean: 0.4
    

--- .class #id

## Note

- R did the test on the smaller proportion group. 
- You can force R to look at the larger group as well:

--- .class #id

## Proportion test on Males

```{r}
table(attr_pop$Gender) %>% 
  rev() %>%
  prop.test()
```

--- .class #id

## Comparing 2 Proportions

- We can then look at the difference in proportion of attrition with females vs males. 
- This can be done with a proportion test as well. 

$$z = \dfrac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}(1-\hat{p})\left(\dfrac{1}{n_1} + \dfrac{1}{n_2}\right)}}$$

--- .class #id

## Comparing 2 Proportions

```{r, eval=F}
table(attr_pop$Gender, attr_pop$Attrition) %>% 
  prop.test()
```

--- .class #id

## Comparing 2 Proportions

```{r, echo=F}
table(attr_pop$Gender, attr_pop$Attrition) %>% 
  prop.test()
```


--- .class #id

## Conclusions

- There does not seem to be a difference based on employees leaving of different genders.
    - *p*-value: 0.29
