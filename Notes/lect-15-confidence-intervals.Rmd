---
title       : Confidence Intervals
author      : Adam J Sullivan 
job         : Assistant Professor of Biostatistics
work        : Brown University
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js # {highlight.js, prettify, highlight}
hitheme     :  github     # 
widgets     : [mathjax, quiz, bootstrap, interactive] # {mathjax, quiz, bootstrap}
ext_widgets : {rCharts: [libraries/nvd3, libraries/leaflet, libraries/dygraphs]}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
logo        : publichealthlogo.png
biglogo     : publichealthlogo.png
assets      : {assets: ../../assets}
---  .segue bg:grey


```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(warning=FALSE)
knitr::opts_chunk$set(message=FALSE)
knitr::opts_chunk$set(results="hold")
knitr::opts_chunk$set(cache=FALSE)
library(ggplot2)
library(fivethirtyeight)
require(tidyverse)
library(broom)
```

# Beginning Confidence Intervals

--- .class #id

## Statistical Estimates


- We have been discussing many types of estimates
    - mean
    - median
    - min
    - max
- These are all what we call point estimates. 
- Estimates are almost always wrong.

--- .class #id

## Problems with Samples

- Each time we sample, we get a different mean. 
- The center of the mean distribution is the true mean of the population but we have no way of knowing if our sample mean is the true mean. 
- How do we deal with this?

--- .class #id

## What can we do? 

- We know we are probably wrong. 
- We wish to understand just how wrong we are. 
- We use a confidence interval (CI)


--- .class #id

## Confidence Intervals

- We quanity how wrong by calculating a **margin of error (MOE)**. 
- We then add and subtract this from our estimate
$$\text{CI} = \text{Point Estimate} \pm \text{MOE}$$


--- .class #id

## Margin of Error

- This is the maximum amount of error we expect in our point estimate. 
- We wish to quantify this within a certain amount of confidence. 
- We call this: 
    - "level of confidence"
    - "confidence level"
- The margin of error is found by using the probability distribution of the point estimate. 

--- .class #id

## Confidence Interval on the Mean

- We already know the distribution of the sample mean. 
- This distribution is normal, so we can find which value of a normal would give us a certain confidence. 
- Suppose we wish to have 95% confidence, then we wish to know what value of the normal distribution give us 95%. 
- We need the values that would then cut 2.5% on the left of and 2.5% on the right. This would then mean 95% in the middle. 
- We can do this in R. 

--- .class #id

## Critical Values

```{r, echo=F, fig.height=2}
ggplot(NULL, aes(c(-3,3))) +
  geom_area(stat = "function", fun = dnorm, fill = "grey80", xlim = c(-4, -1.96)) +
  geom_area(stat = "function", fun = dnorm, fill = "#00998a", xlim = c(-1.96, 1.96)) +
  geom_area(stat = "function", fun = dnorm, fill = "grey80", xlim = c(1.96, 4)) +
  labs(x = "z", y = "") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL)
```


```{r}

# 2.5 Percentile

qnorm(0.025)

# 9.5 Percentile
qnorm(0.975)
```


--- .class #id

## What do we see? 

- The normal is symmetric, so we can see that the values are -1.96 and 1.96. 
- We can just use the positive value here as both will help the same way. 

```{r, echo=F, fig.height=4}
ggplot(NULL, aes(c(-3,3))) +
  geom_area(stat = "function", fun = dnorm, fill = "grey80", xlim = c(-4, -1.96)) +
  geom_area(stat = "function", fun = dnorm, fill = "#00998a", xlim = c(-1.96, 1.96)) +
  geom_area(stat = "function", fun = dnorm, fill = "grey80", xlim = c(1.96, 4)) +
  labs(x = "z", y = "") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = c(-1.96,1.96))
```


--- .class #id

## Making the Confidence Interval

$$\bar{x} \pm z * \dfrac{sigma}{\sqrt{n}}$$

- Where:
    - $\bar{x}$ is the sample mean. 
    - $z$ critical value assocatiated with % of confidence
    - $\sigma$ is population standard deviation. 
    - $n$ is the sample size. 

--- .class #id

## Example

```{R, eval=F}

data <- rbinom(10, 10, 0.3)

mn <- mean(data)
std.dev <- sd(data)

mn - 1.96*std.dev
mn + 1.96*std.dev
```


--- .class #id

## Example

```{R, echo=F}

data <- rbinom(10, 1, 0.3)

mn <- mean(data)
std.dev <- sqrt(10*0.3*0.7)/10

low = mn - 1.96*std.dev
high = mn + 1.96*std.dev

low
high
```



--- .class #id

## What does this mean? 

- It means that 95% of the intervals constructed like this will cover over thepopulation mean. 
- Consider the following app:
- [Agresti Shiny App](https://istats.shinyapps.io/ExploreCoverage/)

--- .class #id

## Interpretation

- The interpretation for the previous example is that we are 95% sure that the interval (`r low`, `r high`) contains the mean. 
- This is not the same as saying there is a 95% chance that the population mean is in this interval. 

--- .class #id

## Interpretation

- While it seems similar, you must remember. 
- There is one true population mean. 
- You construct a sample, then you create a confidence interval. 
- We said that with a 95% confidence interval we know that 95% of these intervals will cover the true mean. 
- The interval is what moves each time. 

--- .class #id

## What about when we do not know $\sigma$? 

- We have shown an example of a binomial where we know the standard devation of the popultion, $\sqrt{n*p*(1-p)}$. 
- What happens when we do not know this? 
- The Student's T Distribution!

--- .class #id

## Student's T Distribution

- Created by a man named Sealy Gosset in 1908. 
- Published under the name "Student" as he was working for Guinness Brewery in Dublin at the time. 
    - Either he didn't want to be known or Guinness did not. 
- His Desire what to understand the distribution of small samples of data. 
- This was for his work in analyzing barley for beer where they may have only very few samples. 

--- .class #id

## Standard Normal

- The standard normal is a normal distribution with mean 0 and variance 1. 
- This is important since if we have:
$$ X\sim N(\mu, \sigma^2)$$
- Then we can standardize this as:

$$Z = \dfrac{X-\mu}{\sigma}$$

--- .class #id

## In Sample Data

- We know that $\bar{X}$ is normal such that
$$ \bar{X}\sim N\left(\mu, \dfrac{\sigma^2}{n}\right)$$
- Then we can make this a standard normal:

$$Z= dfrac{X-\mu}{\sigma/\sqrt{n}}$$

--- .class #id

## Student's t Distribution

$$t_{n-1} = \dfrac{\bar{X}-\mu}{S/\sqrt{n}}$$

- Where:
    - $t_{n-1}$ represents a t distribution with $n-1$ degrees of freedom. 
    - S is the sample variance:
$$S=\dfrac{1}{n-1}\sum_{i=1}^n(x_i-\bar{X})^2$$

--- .class #id

## Student's t Distribution plots

```{R, echo=F}
x <- seq(-7,7, by =0.001)
plot(x, dnorm(x, 0, 1), type="l", col="black", lwd=3, lty=2)
curve(dt(x, 1), add=TRUE, col="red", lwd=3)
curve(dt(x, 3), add=TRUE, col="blue", lwd=3)
curve(dt(x, 8), add=TRUE, col="green", lwd=3)
curve(dt(x, 30), add=TRUE, col="yellow", lwd=3)
legend(-6,0.4,legend=c("Normal","df=1","df=3", "df=8", "df=30"),lty=1,col=c("black", "red", "blue", "green", "yellow"))
```


--- .class #id

## Student's t Confidence Intervals

- Let's assume we have some data that we believe to be a from a normal distribution. 
- We then would wish to create confidence intervals for the mean. 
$$\text{CI} = \text{Point Estimate} \pm \text{MOE}$$
$$ \bar{x} \pm t * \dfrac{S}{\sqrt{n}}$$

--- .class #id

## Example

- We can simulate some data:
- 10 Samples from a $N(63.8, 3.86)$ distribution. 
```{r, eval=F}
data = rnorm(10, 63.8, 3.86)
```
- In real life we have data that is normal yet we do not know $\sigma$. 

--- .class #id

## Margin of Error

- We know that we need to calculate the margin of error. 
$$\text{MOE} = z*\dfrac{\sigma}{\sqrt{n}}$$
- We do not know $\sigma$ but we can calculate $S$. 
$$\text{MOE} = t*\dfrac{S}{\sqrt{n}}$$


--- .class #id

## Critical Value of $t$

```{r}
# 2.5 percentile
qt(0.025, 9)

# 97.5 percentile
qt(0.975, 9)
```

--- .class #id

## What can we see?

- The critical value is 2.26. 
- This is larger than the critical value for the standard normal. 
- Why might this be? 


--- .class #id

## Using R to Calculate

```{R, echo=F}

data = rnorm(10, 63.8, 3.86)

mn <- mean(data)
std.dev <- sd(data)

low = mn - 2.26*std.dev
high = mn + 2.26*std.dev

low
high
```



--- .class #id

## Recap

- We have the concept of a Confidence Interval, which is our sample mean plus or minus some margin of error. 
- In order to find that margin of error we needed to use a critical value. 
- Those critical values came from the "Normal" and "Student's t" Distributions.
- What does that mean? 

--- .class #id

## Further Connection between Z and t

- If you have a t with over 30 samples, you can 

--- .class #id

## Confidence Intervals without Normal Assumption

- What if we wish to find intervals without assuming we have  a normal distribution? 
- We can do a technique called ***bootstrapping***


--- .class #id

## Bootstrapping

- A resampling technique. 
- Similar to the permutation test which we did in lectures 12 and 13. 
- We will describe how this works and then display a couple of ways to do this in R. 

--- .class #id

## Resampling

- Recall the CLT. 
- If you sample from a population over and over again, then the means follow a normal distribution. 
- Most of the time we just have one sample. 
- We are unsure of which sample that is. 


--- .class #id 

## Which sample are we? 

![](figure/lln-coin-100-1.png)

--- .class #id

## Margin of Error

- We have discussed 2 ways to find the margin of error. 
- Sometimes we do not see the ability to obtain a sample like ours over and over again. 
- Other times we are interested in getting a confidence interval on something that is a bit harder for us to consider. 

--- .class #id

## What is bootstrapping? 

![](https://blogs.sas.com/content/iml/files/2018/12/bootstrapSummary.png)

--- .class #id

## Bootstrap Basics

- We sample from the data with replacement. 
- Then for this sample we calculate a statistic. 
- We perform those steps over and over again until we arrive at a distribution of the statistic. 

--- .class #id

## Bootstrap steps 

1. Choose the number of bootstraps to perform. 
2. Choose a sample size. 
3. For each Bootstrap
    a. Draw a sample with replacement equal to the sample size you set. 
    b. Fit a model or calculate a statistic on this data. 
4. Calculate an average or range of values from the multiple bootstraps. 


--- .class #id

## Advantages

- Very simple once you get used to it. 
- Straight forward and does not require extra data. 
- Works with extremely complex things where you may not understand the math enough to find a margin of error. 
- Naturally checks for stability. 
- Many times more accurate than a normal distribution assumption. 

--- .class #id

## Disadvantages

- Works well with small data but does not have any guarantees with small data. 
- Hidden assumptions:
    - independence of samples. 
    - Population is large enough that the sample effect is not too big. 
    - Others depending on what statistic you are bootstrapping. 
    


--- .class #id

## What does it do?

- Basically, bootstrapping treats the data as a population. 
- The we repeatedly draw independent samples to create *bootstrapped* datasets. 
- We sample with replacement, allowing observations to be sampled more than once. 



--- .class #id



![](bootstrap.png)



--- .class #id

## How do we do this?

- Each bootstrap data set $$Z^{*1}, Z^{*2}, \dots, Z^{*B}$$ contains *n* observations, sampled with replacement from the original data set.  
- Each bootstrap is used to compute the estimated statistic we are interested in $\hat\alpha^*$. 


--- .class #id

## Then what?

- We can then use all the bootstrapped data sets to compute the standard error of $$\hat\alpha^{*1}, \hat\alpha^{*2}, \dots, \hat\alpha^{*B}$$ desired statistic as
$$ SE_B(\hat\alpha) = \sqrt{\frac{1}{B-1}\sum^B_{r=1}\bigg(\hat\alpha^{*r}-\frac{1}{B}\sum^B_{r'=1}\hat\alpha^{*r'}\bigg)^2}  \tag{4} $$
- $$SE_B(\hat\alpha)$$ serves as an estimate of the standard error of $$\hat\alpha$$ estimated from the original data set. 

--- .class #id

## Example 1: Estimating the accuracy of a single statistic

- Performing a bootstrap analysis in R entails two steps:
    1. Create a function that computes the statistic of interest.
    2. Use the `boot` function from the [`boot`](http://cran.r-project.org/web/packages/boot/index.html) package to perform the boostrapping

--- .class #id


## The Data

- This data comes from out midterm. 
- We were considering whether or not the number of poor mental health days in the past 30 days was different for those apart of the transgender experience. 
- We first might be interested in understanding the average number of days for both groups. 



--- .class #id


## Doing this with tidyverse

- You will need the following packages:
   
```{r}
library(boot)
library(ggplot2)
library(dplyr)
load("Data/brfss.rda")
```

--- .class #id

## The Data

```{r}
brfss3 <- brfss2 %>%
      filter(trnsgndr_bin=="no") %>%
      select(menthlth)
```

--- .class #id

## Creating our function

- Lets say we wish to have 10000 bootstraps of the data. 

```{R}
get_mean <- function(data, indices){
  d <- data[indices,]
  return(mean(d, na.rm=TRUE))
}
```


--- .class #id

## Generating Bootstraps

- Now we can create the bootstraps
- We will do 1000 bootstraps

```{R, echo=FALSE}
results <- boot(data=brfss3, statistic = get_mean, R=1000)
```








--- .class #id

## Confidence Intervals

```{r}
boot.ci(results, type="basic")
```

--- .class #id

## What about traditional ways?

```{r}
brfss3 %>% 
    summarise(mean(menthlth, na.rm=T), sd(menthlth, na.rm=T))
 qt(0.975, df=6662)

5.498013 - 1.96032 * 8.639915
5.498013 + 1.96032 * 8.639915
```


--- .class #id

## What do we notice?

- Big difference in confidence intervals. 
- Value of t is the same as the normal. 


--- .class #id

## Graph of this


```{r boostrap-ci, echo=F}
data <- as.data.frame(results$t)

bt_ci_lower <- quantile(data$V1, c(0.025))
bt_ci_upper <- quantile(data$V1, c(0.975))
bt_mean <- mean(data$V1)
 
data <- data %>% 
  dplyr::mutate(Color = ifelse(V1 < bt_ci_lower | V1 > bt_ci_upper, "Out of 95% CI", "In 95% CI"))
 
ggplot(data, aes(x = V1, y = 0)) + 
  geom_jitter(aes(color = Color), alpha = 0.6, size = 3, width = 0) + 
  geom_vline(xintercept = round(c(bt_ci_lower, bt_mean, bt_ci_upper),2), linetype = c(2,1,2)) + 
  scale_x_continuous(breaks = round(c(bt_ci_lower, bt_mean, bt_ci_upper),2),
                     labels = c("Lower CI (95%)", "Mean", "Upper CI (95%)"),
                     sec.axis = sec_axis(~., breaks = round(c(bt_ci_lower, bt_mean, bt_ci_upper),2),
                                         labels = round(c(bt_ci_lower, bt_mean, bt_ci_upper),2))) + 
  scale_color_manual(values = c("gray40", "firebrick4")) + 
  theme_void() + 
  theme(legend.title = element_blank(),
        legend.position = "top", 
        legend.text = element_text(size = 14), 
        axis.text.x = element_text(size = 14))
```
